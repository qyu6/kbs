{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdb2593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯·è¾“å…¥æœç´¢å†…å®¹:å¤©å±€\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from os.path import exists\n",
    "import openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "\n",
    "result = 'searchoutput.csv'\n",
    "if exists(result):\n",
    "    os.remove(result)\n",
    "# åˆ›å»ºç»“æœæ–‡ä»¶\n",
    "wbResult = openpyxl.Workbook()\n",
    "wsResult = wbResult.worksheets[0]\n",
    "wsResult.append(['result'])\n",
    "# è¯»å–åŸè¡¨ä¸¤æ¬¡ï¼Œä¸€æ¬¡ç”¨æ¥è¿›è¡Œå»ºè¡¨è¾“å…¥ï¼Œä¸€æ¬¡ç”¨æ¥åšå¯¹åº”çš„è¾“å…¥\n",
    "wb = openpyxl.load_workbook('SourceDB.xlsx')\n",
    "input_excel = 'SourceDB.xlsx'\n",
    "data = pd.read_excel(input_excel)\n",
    "ws = wb.worksheets[0]\n",
    "# åŸè¡¨ç©ºç™½éƒ¨åˆ†ç”¨*å¡«å……\n",
    "for k in range(1,ws.max_column+1):\n",
    "    for i in range(1,ws.max_row+1):\n",
    "        if ws.cell(row=i,column=k).value is None:\n",
    "            ws.cell(i,k,'****')\n",
    "\n",
    "\n",
    "input_word = input(\"è¯·è¾“å…¥æœç´¢å†…å®¹:\").strip().lower()\n",
    "# st.subheader('ğŸ¼[T.Q Knowledge Base]')\n",
    "input_word1 = st.text_input('Â©TAILab|Last release:2022/3/3','')\n",
    "input_word = input_word1.strip().lower()\n",
    "input_word_exist = re.sub(u\"([u4e00-\\u9fa5\\u0030-\\u0039\\u0041-\\u005a\\u0061-\\u007a])\",\"\",input_word)\n",
    "input_word = input_word.split()\n",
    "\n",
    "\n",
    "\n",
    "result_list = []\n",
    "for index,row in enumerate(ws.rows):\n",
    "\n",
    "    if index == 0:\n",
    "        continue\n",
    "    rs_list = list(map(lambda cell: cell.value, row))\n",
    "    list_str = \"\".join('%s' %id for id in rs_list).replace(\"\\n\",\" \").replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"\\r\",\" \").lower()\n",
    "    result_list.append([index, list_str])\n",
    "\n",
    "\n",
    "\n",
    "def search_onebyone(input_word_exist, input_word_list, result_list):\n",
    "    new_list = []\n",
    "    dict_list = []\n",
    "    new_list_count = []\n",
    "    # ç²¾ç¡®åŒ¹é…\n",
    "    for i in range(len(result_list)):\n",
    "        for m in input_word_list:\n",
    "            pattern = m\n",
    "            regex = re.compile(pattern)\n",
    "            nz = regen.search(result_list[i][1])\n",
    "            if nz:\n",
    "                new_list.append([len(nz.group()),nz.stat(),result_list[i][0]-1])\n",
    "                new_list_count.append(result_list[i][0]-1)\n",
    "\n",
    "    new_list = sorted(new_list)\n",
    "    new_index = [x for _,_,x in new_list]\n",
    "    new_index = sorted(set(new_index),key=new_index.index)\n",
    "\n",
    "    # è®¡æ•°ï¼Œåªæœ‰å½“è¾“å…¥çš„å…¨éƒ¨å•è¯å…¨éƒ¨å‡ºç°ä»¥åï¼Œæ‰å–å‡º\n",
    "    dict_list.append([k for k,v in Counter(new_list_count).items() if v == len(input_word_list)])\n",
    "    for m in dict_list:\n",
    "        result_index = m\n",
    "    temp = [j for j in new_index if j in result_index]\n",
    "    return temp\n",
    "result = search_onebyone(input_word_exist, input_word, result_list)\n",
    "\n",
    "\n",
    "\n",
    "def display_highlighted_words(df, keywords):\n",
    "    head = \"\"\"\n",
    "    <talbe>\n",
    "        <thead>\n",
    "            \"\"\" + \\\n",
    "                \"\".join([\"<th> %s </th>\" % c for c in df.columns])\\\n",
    "                + \"\"\"\n",
    "        </thead>\n",
    "    </table>\"\"\"\n",
    "\n",
    "    head = \"\"\"\n",
    "    <table>\n",
    "        <thead>\n",
    "            <th> Keywords </th><th> Content </th>\n",
    "        </thead>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "\n",
    "    for i,r in df.iterrows():\n",
    "        row = \"<tr>\"\n",
    "        for c in df.columns:\n",
    "            matches = []\n",
    "            for k in keywords:\n",
    "                for match in re.finditer(k, str(r[c])):\n",
    "                    matches.append(match)\n",
    "\n",
    "            # reverse sorting\n",
    "            matches = sorted(matches, key = lambda x: x.start(), reverse=True)\n",
    "\n",
    "            # building HTML row\n",
    "            cell = str(r[c])\n",
    "\n",
    "            # print(cell)\n",
    "            for match in matches:\n",
    "                cell = cell[:match.start()] +\\\n",
    "                    \"<span style='color:red;background-color:yellow'> %s </span>\" % cell[match.start():match.end()] +\\\n",
    "                    cell[match.end():]\n",
    "\n",
    "            row += \"<td> %s </td>\" % cell\n",
    "\n",
    "        row += \"</tr>\"\n",
    "\n",
    "        head += row\n",
    "\n",
    "\n",
    "        head += \"</tbody></table>\"\n",
    "\n",
    "        return head\n",
    "\n",
    "# htmlcode1 = display_highlighted_words(dftest, input_word)\n",
    "# st.markdown(htmlcode1, unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "if len(input_word)>0:\n",
    "    display(data.loc[(x for x in result)])\n",
    "\n",
    "\n",
    "data.loc[(x for x in result)].to_csv('searchoutput.csv', encoding= 'utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
